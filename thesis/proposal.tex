\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{textcomp} % Degree symbol
\usepackage[colorlinks, allcolors=blue]{hyperref}
\bibliographystyle{apalike}

%opening
\title{Fuzzy land cover classification using PROBA-V satellite data}
\author{Dainius Masili\=unas}

\begin{document}

\maketitle

\section{Introduction}

While classification uncertainty is not a direct measure of class membership \cite{sytze2000fuzzyset}, they are nonetheless correlated. As such, it has been used by numerous authors as a proxy indicator of class membership, achieving satisfactory classification accuracy \cite{foody2002accuracy}.

For hard classification, accuracy assessment is rather straight-forward: typically a confusion matrix is employed for this purpose, showing how many pixels in the image have been classified correctly, and how many incorrectly. Such a matrix makes it simple to tell which classes are hard to discern from one another, as well as allows for deriving statistics such as users' accuracy, producers' accuracy, and total accuracy. Unfortunately, a standard confusion matrix is not applicable in the context of fuzzy classification, since misclassification in this case is not absolute, but rather a matter of degree \cite{foody2002accuracy}. Several solutions, such as cross-entropy, mutual information, and distance have been suggested as alternatives for fuzzy classification accuracy assessment \cite{lu2007methods}.

There is a number of different classification methods, but only several of them are suitable to be used for fuzzy classification \cite{nath2014methods}. The two methods most commonly used in scientific literature are fuzzy c-means and neural networks \cite{zhang2001fullyfuzzy}. Neural networks in particular are well-suited for fuzzy classification, since they allow multiple continuous output as well as input variables in a single model \cite{foody1997fuzzynnet}. Fuzzy c-means, also known as fuzzy k-means or soft k-means, is a statistical method that relies on the proximity of pixels in feature space to class centres, and thus is also suitable for fully fuzzy classification. However, since k-means is an unsupervised classification algorithm, the ability to make use of training data in fuzzy c-means is limited to determining class centres with more precision \cite{hengl2004fuzzycmeans}, and as such it is effectively similar to maximum likelihood classification.

In addition, other algorithms that provide a measure of uncertainty about class membership can be used, such as the ratio of individual tree votes of Random Forest. Furthermore, algorithms that can handle continuous variables, but only one response variable (such as Random Forest), can be used as well, as long as the data is postprocessed at a pixel level to conform to physical constraints (class membership must be between 0 and 100\% and sum up to 100\%). Random Forest has generally been reported to give higher or equal accuracy results compared to other algorithms in hard classification scenarios using satellite imagery similar to that of PROBA-V \cite{duro2012algorithmcomparison}. Random Forest regression was also shown to perform as well as other algorithms in fuzzy classification scenarios \cite{walton2008subpixelrf}, although it is used in much fewer studies on fuzzy classification than the other algorithms mentioned previously.

Given the large number of options for the algorithms, all very different approaches to the same problem, the thesis will focus on assessing their performance when applied to real, large scale satellite imagery from the PROBA-V satellite spanning the gradient between boreal forests and deciduous forests in Europe. The algorithms tested will be:

\begin{itemize}
 \item Fuzzy c-means: semi-supervised, fully fuzzy, single-model statistical method
 \item Fuzzy neural network: fully supervised, fully fuzzy, single-model machine learning method
 \item Random forest regression: fully supervised, fully fuzzy, multiple-model machine learning method
 \item Random forest classification: fully supervised, partially fuzzy, single-model machine learning method
\end{itemize}

Visualisation of the fuzzy classification results is also challenging, since each class effectively is a single-channel raster of its own. Three such classes can easily be combined into RGB channels for visualisation, but with more classes it is no longer possible. There have been attempts to develop a method based on the hue, saturation and intensity colour model to allow for more distinct classes to be visualised on a single raster \cite{hengl2004fuzzycmeans}. There is also a possibility of hardening the classification when high accuracy visualisation is not needed, and making use of multiple RGB rasters side-by-side when it is needed.

\section{Problem definition and research questions}

Global land cover classification is an important research topic, with a number of different approaches having been tested \cite{hansen2000hardtree}. New and improved satellite sensors allow for improving existing classification, with both spatial and temporal resolution of the remote sensing imagery getting improved over time. At the moment the PROBA-V mission by the European Space Agency produces imagery that is a good fit for use in land cover classification. It is well-suited for time series analysis, because it has an archive that goes back to 2013, as well as a fast revisit time of 2 days for full global coverage (1 day for locations above 35\textdegree{} latitude) \cite{dierckx2014probav}. It also has moderate spatial resolution (100 by 100 metres, 300 by 300 metres and 1 by 1 kilometre pixel size products) \cite{probavguide}.

Since PROBA-V is a relatively new satellite, so far there have been few studies using it for land cover classification. A number of studies have used simulated PROBA-V data in preparation for its launch \cite{stathakis2014probavurban} \cite{roumenina2013probavcrops}. After launch, most studies have focused on its potential for crop classification \cite{roumenina2015probavcrops} \cite{durgun2016crop} \cite{lambert2016cropland}. All of these studies have used the traditional hard classification.



\begin{itemize}
 \item Which algorithm gives the most accurate fuzzy classification results?
 \item Which classes are the most difficult to discern from others?
 \item How does the processing time differ among the different algorithms, when applied to large-scale imagery?
 \item What variables are most important for large-scale fuzzy classification?
\end{itemize}

\section{Methods}

\subsection{Sample acquisition}

Samples for training and validation will be obtained manually, by following a procedure based on \cite{defries1998training}:
\begin{itemize}
 \item The chosen PROBA-V raster tile will be imported into QGIS as a boundary reference.
 \item A high number of points (around 500) will be generated randomly within the boundaries of the raster tile.
 \item Other layers, like Google Satellite (Digital Globe), Bing Maps, SENTINEL-2 and OpenStreetMap, as well as validation points from Geo Wiki validation contest II, will be put on top of the PROBA-V raster tile.
 \item A new point layer for determined class information will be created.
 \item For each randomly generated point, a new point will be added to the new point layer in the centre of the associated PROBA-V pixel.
 \item The new point will have its class fraction filled out for all the classes (one attribute per class). This will be determined using visual inspection of all the aforementioned layers.
 \item The process will be repeated until each class has a representative sample of pixels classified.
\end{itemize}

Some of the randomly generated points may be skipped, if enough samples of the particular land cover type had already been collected (for instance, water), in favour of those types that do not have enough or are more difficult to discern from remote sensing. Priority will also be given to endmember pixels, as some classification methods can only be trained on endmember pixels.

The sample points will then be imported into R as separate variables.

\section{Time schedule and feasibility}

\bibliography{bibliography}

\end{document}

%Training: Forest + grass + urban + water ~ Blue + Red + NIR + SWIR + Period + Phase + Amplitude + Etc
%To predict: . ~ Blue + Red + NIR + SWIR + Period + Phase + Amplitude + Etc

%c-means (fully fuzzy, partially supervised)
%neural networks (partially or fully fuzzy, fully supervised)
%random forest (partially fuzzy or multiple, fully supervised)
